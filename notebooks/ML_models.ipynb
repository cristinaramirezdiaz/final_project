{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(r\"../data/final.csv\")\n",
    "features = df.drop('loan_status', axis=1)\n",
    "target = df['loan_status'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>married</th>\n",
       "      <th>dependents</th>\n",
       "      <th>education</th>\n",
       "      <th>self_employed</th>\n",
       "      <th>income</th>\n",
       "      <th>loan_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>2990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41000.0</td>\n",
       "      <td>1220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>91000.0</td>\n",
       "      <td>2970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82000.0</td>\n",
       "      <td>3070.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>2420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34800.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4786</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49272.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4787</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96864.0</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90996.0</td>\n",
       "      <td>187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4789</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54996.0</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4790 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  married  dependents  education  self_employed   income  \\\n",
       "0          0        0           2          1              0  96000.0   \n",
       "1          0        1           0          0              1  41000.0   \n",
       "2          0        1           3          1              0  91000.0   \n",
       "3          0        1           3          1              0  82000.0   \n",
       "4          0        0           5          0              1  98000.0   \n",
       "...      ...      ...         ...        ...            ...      ...   \n",
       "4785       1        0           0          1              0  34800.0   \n",
       "4786       0        1           3          1              0  49272.0   \n",
       "4787       0        1           1          1              0  96864.0   \n",
       "4788       0        1           2          1              0  90996.0   \n",
       "4789       1        0           0          1              1  54996.0   \n",
       "\n",
       "      loan_amount  \n",
       "0          2990.0  \n",
       "1          1220.0  \n",
       "2          2970.0  \n",
       "3          3070.0  \n",
       "4          2420.0  \n",
       "...           ...  \n",
       "4785         71.0  \n",
       "4786         40.0  \n",
       "4787        253.0  \n",
       "4788        187.0  \n",
       "4789        133.0  \n",
       "\n",
       "[4790 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Approved\n",
       "1       Rejected\n",
       "2       Rejected\n",
       "3       Rejected\n",
       "4       Rejected\n",
       "          ...   \n",
       "4785    Approved\n",
       "4786    Approved\n",
       "4787    Approved\n",
       "4788    Approved\n",
       "4789    Rejected\n",
       "Name: loan_status, Length: 4790, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Model          Outliers        Scaling     Feature Set  \\\n",
      "0    Logistic Regression     With Outliers     No Scaling    All Features   \n",
      "1          Decision Tree     With Outliers     No Scaling    All Features   \n",
      "2          Random Forest     With Outliers     No Scaling    All Features   \n",
      "3                    SVM     With Outliers     No Scaling    All Features   \n",
      "4                    KNN     With Outliers     No Scaling    All Features   \n",
      "..                   ...               ...            ...             ...   \n",
      "115  Logistic Regression  Without Outliers  Normalization  No Family Size   \n",
      "116        Decision Tree  Without Outliers  Normalization  No Family Size   \n",
      "117        Random Forest  Without Outliers  Normalization  No Family Size   \n",
      "118                  SVM  Without Outliers  Normalization  No Family Size   \n",
      "119                  KNN  Without Outliers  Normalization  No Family Size   \n",
      "\n",
      "     Accuracy  \n",
      "0    0.616910  \n",
      "1    0.535491  \n",
      "2    0.551148  \n",
      "3    0.616910  \n",
      "4    0.533403  \n",
      "..        ...  \n",
      "115  0.635887  \n",
      "116  0.548793  \n",
      "117  0.556139  \n",
      "118  0.635887  \n",
      "119  0.555089  \n",
      "\n",
      "[120 rows x 5 columns]\n",
      "\n",
      "Best performing model:\n",
      "Model          Logistic Regression\n",
      "Outliers          Without Outliers\n",
      "Scaling                 No Scaling\n",
      "Feature Set           All Features\n",
      "Accuracy                  0.635887\n",
      "Name: 60, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Función para eliminar outliers\n",
    "def remove_outliers(df, columns, z_threshold=3):\n",
    "    columns = [col for col in columns if col in df.columns]\n",
    "    return df[(np.abs(stats.zscore(df[columns])) < z_threshold).all(axis=1)]\n",
    "\n",
    "# Definir diferentes conjuntos de características\n",
    "all_features = features.columns.tolist()\n",
    "numeric_features = [col for col in ['dependents', 'income', 'loan_amount'] if col in features.columns]\n",
    "categorical_features = [col for col in ['gender', 'married', 'education', 'self_employed'] if col in features.columns]\n",
    "\n",
    "feature_sets = {\n",
    "    'All Features': all_features,\n",
    "    'Numeric Only': numeric_features,\n",
    "    'Categorical Only': categorical_features,\n",
    "    'No Family Size': [col for col in all_features if col != 'Family_Size']\n",
    "}\n",
    "\n",
    "# Definir modelos\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'SVM': SVC(random_state=42),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Preparar resultados en un DataFrame\n",
    "results = []\n",
    "\n",
    "# Iterar a través de diferentes escenarios\n",
    "for outliers in ['With Outliers', 'Without Outliers']:\n",
    "    for scaling in ['No Scaling', 'Standardization', 'Normalization']:\n",
    "        for feature_set_name, features_list in feature_sets.items():\n",
    "            # Preparar los datos\n",
    "            X_subset = features[features_list]\n",
    "            y_subset = target\n",
    "            \n",
    "            if outliers == 'Without Outliers':\n",
    "                X_subset = remove_outliers(X_subset, numeric_features)\n",
    "                y_subset = y_subset[X_subset.index]\n",
    "            \n",
    "            # Dividir los datos en train y test\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_subset, y_subset, test_size=0.2, random_state=42)\n",
    "            \n",
    "            # Aplicar escalado si es necesario\n",
    "            if scaling == 'Standardization':\n",
    "                scaler = StandardScaler()\n",
    "                X_train_scaled = scaler.fit_transform(X_train)\n",
    "                X_test_scaled = scaler.transform(X_test)\n",
    "            elif scaling == 'Normalization':\n",
    "                scaler = MinMaxScaler()\n",
    "                X_train_scaled = scaler.fit_transform(X_train)\n",
    "                X_test_scaled = scaler.transform(X_test)\n",
    "            else:\n",
    "                X_train_scaled = X_train\n",
    "                X_test_scaled = X_test\n",
    "            \n",
    "            # Entrenar y evaluar modelos\n",
    "            for model_name, model in models.items():\n",
    "                model.fit(X_train_scaled, y_train)\n",
    "                y_pred = model.predict(X_test_scaled)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                \n",
    "                results.append({\n",
    "                    'Model': model_name,\n",
    "                    'Outliers': outliers,\n",
    "                    'Scaling': scaling,\n",
    "                    'Feature Set': feature_set_name,\n",
    "                    'Accuracy': accuracy\n",
    "                })\n",
    "\n",
    "# Convertir resultados a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Imprimir resumen\n",
    "print(results_df)\n",
    "\n",
    "# Encontrar el mejor modelo\n",
    "best_model = results_df.loc[results_df['Accuracy'].idxmax()]\n",
    "print(\"\\nBest performing model:\")\n",
    "print(best_model)\n",
    "\n",
    "# Opcional: Guardar los resultados en un CSV\n",
    "results_df.to_csv('../data/model_comparison_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Outliers</th>\n",
       "      <th>Scaling</th>\n",
       "      <th>Feature Set</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SVM</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.617954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVM</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.617954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SVM</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SVM</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>SVM</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>SVM</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVM</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SVM</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SVM</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SVM</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.616910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.590766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.586569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>KNN</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.568894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>KNN</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.563674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>KNN</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.563674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.562434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.562434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.560336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.560336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KNN</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.558455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>KNN</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.558455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.556139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.556139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.556139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.555089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.555089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.555089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.555089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.553236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.553236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.552991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.551941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.551941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.551941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.551941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.551941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.551941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.551148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.551148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.548793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.548793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.547744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.547744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.545929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.545929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>KNN</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.543841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.539666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.539666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.538300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.535491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.535491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.534447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.534447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KNN</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.533403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.533403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.533403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.531315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.530955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.528184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>KNN</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.528184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.528184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNN</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.528184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.525052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.524659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.524008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.518789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.517745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>KNN</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.515658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>Numeric Only</td>\n",
       "      <td>0.515658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>Categorical Only</td>\n",
       "      <td>0.515658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model          Outliers          Scaling       Feature Set  \\\n",
       "60   Logistic Regression  Without Outliers       No Scaling      All Features   \n",
       "98                   SVM  Without Outliers  Standardization    No Family Size   \n",
       "63                   SVM  Without Outliers       No Scaling      All Features   \n",
       "65   Logistic Regression  Without Outliers       No Scaling      Numeric Only   \n",
       "68                   SVM  Without Outliers       No Scaling      Numeric Only   \n",
       "75   Logistic Regression  Without Outliers       No Scaling    No Family Size   \n",
       "78                   SVM  Without Outliers       No Scaling    No Family Size   \n",
       "80   Logistic Regression  Without Outliers  Standardization      All Features   \n",
       "85   Logistic Regression  Without Outliers  Standardization      Numeric Only   \n",
       "88                   SVM  Without Outliers  Standardization      Numeric Only   \n",
       "95   Logistic Regression  Without Outliers  Standardization    No Family Size   \n",
       "83                   SVM  Without Outliers  Standardization      All Features   \n",
       "100  Logistic Regression  Without Outliers    Normalization      All Features   \n",
       "105  Logistic Regression  Without Outliers    Normalization      Numeric Only   \n",
       "108                  SVM  Without Outliers    Normalization      Numeric Only   \n",
       "118                  SVM  Without Outliers    Normalization    No Family Size   \n",
       "103                  SVM  Without Outliers    Normalization      All Features   \n",
       "115  Logistic Regression  Without Outliers    Normalization    No Family Size   \n",
       "38                   SVM     With Outliers  Standardization    No Family Size   \n",
       "23                   SVM     With Outliers  Standardization      All Features   \n",
       "113                  SVM  Without Outliers    Normalization  Categorical Only   \n",
       "48                   SVM     With Outliers    Normalization      Numeric Only   \n",
       "50   Logistic Regression     With Outliers    Normalization  Categorical Only   \n",
       "51         Decision Tree     With Outliers    Normalization  Categorical Only   \n",
       "52         Random Forest     With Outliers    Normalization  Categorical Only   \n",
       "53                   SVM     With Outliers    Normalization  Categorical Only   \n",
       "55   Logistic Regression     With Outliers    Normalization    No Family Size   \n",
       "58                   SVM     With Outliers    Normalization    No Family Size   \n",
       "72         Random Forest  Without Outliers       No Scaling  Categorical Only   \n",
       "70   Logistic Regression  Without Outliers       No Scaling  Categorical Only   \n",
       "71         Decision Tree  Without Outliers       No Scaling  Categorical Only   \n",
       "73                   SVM  Without Outliers       No Scaling  Categorical Only   \n",
       "112        Random Forest  Without Outliers    Normalization  Categorical Only   \n",
       "111        Decision Tree  Without Outliers    Normalization  Categorical Only   \n",
       "110  Logistic Regression  Without Outliers    Normalization  Categorical Only   \n",
       "43                   SVM     With Outliers    Normalization      All Features   \n",
       "90   Logistic Regression  Without Outliers  Standardization  Categorical Only   \n",
       "91         Decision Tree  Without Outliers  Standardization  Categorical Only   \n",
       "92         Random Forest  Without Outliers  Standardization  Categorical Only   \n",
       "93                   SVM  Without Outliers  Standardization  Categorical Only   \n",
       "45   Logistic Regression     With Outliers    Normalization      Numeric Only   \n",
       "0    Logistic Regression     With Outliers       No Scaling      All Features   \n",
       "20   Logistic Regression     With Outliers  Standardization      All Features   \n",
       "8                    SVM     With Outliers       No Scaling      Numeric Only   \n",
       "30   Logistic Regression     With Outliers  Standardization  Categorical Only   \n",
       "12         Random Forest     With Outliers       No Scaling  Categorical Only   \n",
       "31         Decision Tree     With Outliers  Standardization  Categorical Only   \n",
       "11         Decision Tree     With Outliers       No Scaling  Categorical Only   \n",
       "13                   SVM     With Outliers       No Scaling  Categorical Only   \n",
       "32         Random Forest     With Outliers  Standardization  Categorical Only   \n",
       "10   Logistic Regression     With Outliers       No Scaling  Categorical Only   \n",
       "25   Logistic Regression     With Outliers  Standardization      Numeric Only   \n",
       "15   Logistic Regression     With Outliers       No Scaling    No Family Size   \n",
       "33                   SVM     With Outliers  Standardization  Categorical Only   \n",
       "35   Logistic Regression     With Outliers  Standardization    No Family Size   \n",
       "5    Logistic Regression     With Outliers       No Scaling      Numeric Only   \n",
       "3                    SVM     With Outliers       No Scaling      All Features   \n",
       "18                   SVM     With Outliers       No Scaling    No Family Size   \n",
       "40   Logistic Regression     With Outliers    Normalization      All Features   \n",
       "28                   SVM     With Outliers  Standardization      Numeric Only   \n",
       "109                  KNN  Without Outliers    Normalization      Numeric Only   \n",
       "89                   KNN  Without Outliers  Standardization      Numeric Only   \n",
       "29                   KNN     With Outliers  Standardization      Numeric Only   \n",
       "59                   KNN     With Outliers    Normalization    No Family Size   \n",
       "44                   KNN     With Outliers    Normalization      All Features   \n",
       "82         Random Forest  Without Outliers  Standardization      All Features   \n",
       "97         Random Forest  Without Outliers  Standardization    No Family Size   \n",
       "77         Random Forest  Without Outliers       No Scaling    No Family Size   \n",
       "62         Random Forest  Without Outliers       No Scaling      All Features   \n",
       "24                   KNN     With Outliers  Standardization      All Features   \n",
       "39                   KNN     With Outliers  Standardization    No Family Size   \n",
       "69                   KNN  Without Outliers       No Scaling      Numeric Only   \n",
       "102        Random Forest  Without Outliers    Normalization      All Features   \n",
       "117        Random Forest  Without Outliers    Normalization    No Family Size   \n",
       "67         Random Forest  Without Outliers       No Scaling      Numeric Only   \n",
       "104                  KNN  Without Outliers    Normalization      All Features   \n",
       "87         Random Forest  Without Outliers  Standardization      Numeric Only   \n",
       "119                  KNN  Without Outliers    Normalization    No Family Size   \n",
       "37         Random Forest     With Outliers  Standardization    No Family Size   \n",
       "22         Random Forest     With Outliers  Standardization      All Features   \n",
       "107        Random Forest  Without Outliers    Normalization      Numeric Only   \n",
       "96         Decision Tree  Without Outliers  Standardization    No Family Size   \n",
       "81         Decision Tree  Without Outliers  Standardization      All Features   \n",
       "64                   KNN  Without Outliers       No Scaling      All Features   \n",
       "79                   KNN  Without Outliers       No Scaling    No Family Size   \n",
       "76         Decision Tree  Without Outliers       No Scaling    No Family Size   \n",
       "61         Decision Tree  Without Outliers       No Scaling      All Features   \n",
       "2          Random Forest     With Outliers       No Scaling      All Features   \n",
       "17         Random Forest     With Outliers       No Scaling    No Family Size   \n",
       "101        Decision Tree  Without Outliers    Normalization      All Features   \n",
       "116        Decision Tree  Without Outliers    Normalization    No Family Size   \n",
       "84                   KNN  Without Outliers  Standardization      All Features   \n",
       "99                   KNN  Without Outliers  Standardization    No Family Size   \n",
       "57         Random Forest     With Outliers    Normalization    No Family Size   \n",
       "42         Random Forest     With Outliers    Normalization      All Features   \n",
       "49                   KNN     With Outliers    Normalization      Numeric Only   \n",
       "36         Decision Tree     With Outliers  Standardization    No Family Size   \n",
       "21         Decision Tree     With Outliers  Standardization      All Features   \n",
       "86         Decision Tree  Without Outliers  Standardization      Numeric Only   \n",
       "16         Decision Tree     With Outliers       No Scaling    No Family Size   \n",
       "1          Decision Tree     With Outliers       No Scaling      All Features   \n",
       "41         Decision Tree     With Outliers    Normalization      All Features   \n",
       "56         Decision Tree     With Outliers    Normalization    No Family Size   \n",
       "19                   KNN     With Outliers       No Scaling    No Family Size   \n",
       "9                    KNN     With Outliers       No Scaling      Numeric Only   \n",
       "4                    KNN     With Outliers       No Scaling      All Features   \n",
       "7          Random Forest     With Outliers       No Scaling      Numeric Only   \n",
       "66         Decision Tree  Without Outliers       No Scaling      Numeric Only   \n",
       "114                  KNN  Without Outliers    Normalization  Categorical Only   \n",
       "54                   KNN     With Outliers    Normalization  Categorical Only   \n",
       "74                   KNN  Without Outliers       No Scaling  Categorical Only   \n",
       "14                   KNN     With Outliers       No Scaling  Categorical Only   \n",
       "47         Random Forest     With Outliers    Normalization      Numeric Only   \n",
       "106        Decision Tree  Without Outliers    Normalization      Numeric Only   \n",
       "27         Random Forest     With Outliers  Standardization      Numeric Only   \n",
       "46         Decision Tree     With Outliers    Normalization      Numeric Only   \n",
       "26         Decision Tree     With Outliers  Standardization      Numeric Only   \n",
       "34                   KNN     With Outliers  Standardization  Categorical Only   \n",
       "6          Decision Tree     With Outliers       No Scaling      Numeric Only   \n",
       "94                   KNN  Without Outliers  Standardization  Categorical Only   \n",
       "\n",
       "     Accuracy  \n",
       "60   0.635887  \n",
       "98   0.635887  \n",
       "63   0.635887  \n",
       "65   0.635887  \n",
       "68   0.635887  \n",
       "75   0.635887  \n",
       "78   0.635887  \n",
       "80   0.635887  \n",
       "85   0.635887  \n",
       "88   0.635887  \n",
       "95   0.635887  \n",
       "83   0.635887  \n",
       "100  0.635887  \n",
       "105  0.635887  \n",
       "108  0.635887  \n",
       "118  0.635887  \n",
       "103  0.635887  \n",
       "115  0.635887  \n",
       "38   0.617954  \n",
       "23   0.617954  \n",
       "113  0.616910  \n",
       "48   0.616910  \n",
       "50   0.616910  \n",
       "51   0.616910  \n",
       "52   0.616910  \n",
       "53   0.616910  \n",
       "55   0.616910  \n",
       "58   0.616910  \n",
       "72   0.616910  \n",
       "70   0.616910  \n",
       "71   0.616910  \n",
       "73   0.616910  \n",
       "112  0.616910  \n",
       "111  0.616910  \n",
       "110  0.616910  \n",
       "43   0.616910  \n",
       "90   0.616910  \n",
       "91   0.616910  \n",
       "92   0.616910  \n",
       "93   0.616910  \n",
       "45   0.616910  \n",
       "0    0.616910  \n",
       "20   0.616910  \n",
       "8    0.616910  \n",
       "30   0.616910  \n",
       "12   0.616910  \n",
       "31   0.616910  \n",
       "11   0.616910  \n",
       "13   0.616910  \n",
       "32   0.616910  \n",
       "10   0.616910  \n",
       "25   0.616910  \n",
       "15   0.616910  \n",
       "33   0.616910  \n",
       "35   0.616910  \n",
       "5    0.616910  \n",
       "3    0.616910  \n",
       "18   0.616910  \n",
       "40   0.616910  \n",
       "28   0.616910  \n",
       "109  0.590766  \n",
       "89   0.586569  \n",
       "29   0.568894  \n",
       "59   0.563674  \n",
       "44   0.563674  \n",
       "82   0.562434  \n",
       "97   0.562434  \n",
       "77   0.560336  \n",
       "62   0.560336  \n",
       "24   0.558455  \n",
       "39   0.558455  \n",
       "69   0.556139  \n",
       "102  0.556139  \n",
       "117  0.556139  \n",
       "67   0.555089  \n",
       "104  0.555089  \n",
       "87   0.555089  \n",
       "119  0.555089  \n",
       "37   0.553236  \n",
       "22   0.553236  \n",
       "107  0.552991  \n",
       "96   0.551941  \n",
       "81   0.551941  \n",
       "64   0.551941  \n",
       "79   0.551941  \n",
       "76   0.551941  \n",
       "61   0.551941  \n",
       "2    0.551148  \n",
       "17   0.551148  \n",
       "101  0.548793  \n",
       "116  0.548793  \n",
       "84   0.547744  \n",
       "99   0.547744  \n",
       "57   0.545929  \n",
       "42   0.545929  \n",
       "49   0.543841  \n",
       "36   0.539666  \n",
       "21   0.539666  \n",
       "86   0.538300  \n",
       "16   0.535491  \n",
       "1    0.535491  \n",
       "41   0.534447  \n",
       "56   0.534447  \n",
       "19   0.533403  \n",
       "9    0.533403  \n",
       "4    0.533403  \n",
       "7    0.531315  \n",
       "66   0.530955  \n",
       "114  0.528184  \n",
       "54   0.528184  \n",
       "74   0.528184  \n",
       "14   0.528184  \n",
       "47   0.525052  \n",
       "106  0.524659  \n",
       "27   0.524008  \n",
       "46   0.518789  \n",
       "26   0.517745  \n",
       "34   0.515658  \n",
       "6    0.515658  \n",
       "94   0.515658  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "results_df.sort_values(by = \"Accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Outliers</th>\n",
       "      <th>Scaling</th>\n",
       "      <th>Feature Set</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Pasting</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.528184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.527140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Pasting</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.517314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Pasting</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.516264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Pasting</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.514166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model          Outliers          Scaling     Feature Set  \\\n",
       "0   Logistic Regression  Without Outliers       No Scaling    All Features   \n",
       "1                   SVM  Without Outliers  Standardization  No Family Size   \n",
       "2   Logistic Regression  Without Outliers       No Scaling  No Family Size   \n",
       "3                   SVM  Without Outliers       No Scaling  No Family Size   \n",
       "4   Logistic Regression  Without Outliers  Standardization    All Features   \n",
       "..                  ...               ...              ...             ...   \n",
       "91              Pasting     With Outliers  Standardization    All Features   \n",
       "92        Random Forest     With Outliers  Standardization  No Family Size   \n",
       "93              Pasting  Without Outliers    Normalization  No Family Size   \n",
       "94              Pasting  Without Outliers       No Scaling  No Family Size   \n",
       "95              Pasting  Without Outliers  Standardization  No Family Size   \n",
       "\n",
       "    Accuracy  \n",
       "0   0.635887  \n",
       "1   0.635887  \n",
       "2   0.635887  \n",
       "3   0.635887  \n",
       "4   0.635887  \n",
       "..       ...  \n",
       "91  0.528184  \n",
       "92  0.527140  \n",
       "93  0.517314  \n",
       "94  0.516264  \n",
       "95  0.514166  \n",
       "\n",
       "[96 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Supongamos que tenemos una función para eliminar outliers\n",
    "def remove_outliers(df, threshold=3):\n",
    "    # Eliminar filas con valores fuera del rango del umbral de desviación estándar\n",
    "    return df[(np.abs(df - df.mean()) / df.std()) < threshold].dropna()\n",
    "\n",
    "# Definir los modelos\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'SVM': SVC(),\n",
    "    'Bagging with Decision Tree': BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Pasting': BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, bootstrap=False, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Definir escaladores\n",
    "scalers = {\n",
    "    'No Scaling': None,\n",
    "    'Standardization': StandardScaler(),\n",
    "    'Normalization': MinMaxScaler()\n",
    "}\n",
    "\n",
    "# Definir diferentes conjuntos de características\n",
    "feature_sets = {\n",
    "    'All Features': features,\n",
    "    'No Family Size': features.drop(columns=['dependents']) # Cambia esto según el nombre exacto de la columna\n",
    "}\n",
    "\n",
    "# Inicializar lista para almacenar los resultados\n",
    "results = []\n",
    "\n",
    "# Loop para entrenar modelos con diferentes combinaciones\n",
    "for outliers_option in ['With Outliers', 'Without Outliers']:\n",
    "    # Eliminar outliers si corresponde\n",
    "    data = features.copy()\n",
    "    if outliers_option == 'Without Outliers':\n",
    "        data = remove_outliers(data)\n",
    "    \n",
    "    # Obtener las etiquetas (target) correspondientes\n",
    "    target_data = target.loc[data.index]\n",
    "\n",
    "    for scaling_option, scaler in scalers.items():\n",
    "        # Escalar los datos si corresponde\n",
    "        scaled_data = data.copy()\n",
    "        if scaler:\n",
    "            scaled_data = pd.DataFrame(scaler.fit_transform(scaled_data), columns=data.columns)\n",
    "        \n",
    "        for feature_set_name, feature_set in feature_sets.items():\n",
    "            # Usar las características correspondientes\n",
    "            if feature_set_name == 'All Features':\n",
    "                X = scaled_data\n",
    "            else:\n",
    "                X = scaled_data[feature_set.columns]\n",
    "\n",
    "            # Dividir el conjunto de datos\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, target_data, test_size=0.2, random_state=42)\n",
    "\n",
    "            # Entrenar y evaluar cada modelo\n",
    "            for model_name, model in models.items():\n",
    "                # Entrenar el modelo\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                # Hacer predicciones\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                # Calcular la precisión\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "                # Almacenar los resultados\n",
    "                results.append({\n",
    "                    'Model': model_name,\n",
    "                    'Outliers': outliers_option,\n",
    "                    'Scaling': scaling_option,\n",
    "                    'Feature Set': feature_set_name,\n",
    "                    'Accuracy': accuracy\n",
    "                })\n",
    "\n",
    "# Convertir la lista de resultados a un DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n",
    "# Mostrar los resultados\n",
    "results_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros para Logistic Regression: {'logistic__C': 0.1, 'logistic__solver': 'liblinear'}\n",
      "Mejor accuracy para Logistic Regression: 0.6282\n",
      "Mejores parámetros para SVM: {'svm__C': 0.05, 'svm__kernel': 'linear'}\n",
      "Mejor accuracy para SVM: 0.6282\n",
      "Accuracy en el conjunto de prueba para Logistic Regression: 0.6359\n",
      "Accuracy en el conjunto de prueba para SVM: 0.6359\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Definir el espacio de hiperparámetros para Logistic Regression\n",
    "logistic_params = {\n",
    "    'logistic__C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],  # Regularización\n",
    "    'logistic__solver': ['liblinear', 'saga']  # Algoritmos de optimización\n",
    "}\n",
    "\n",
    "# Definir el espacio de hiperparámetros para SVM\n",
    "svm_params = {\n",
    "    'svm__C': [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],  # Regularización\n",
    "    'svm__kernel': ['linear', 'rbf']  # Tipos de kernel\n",
    "}\n",
    "\n",
    "# Definir los modelos en un Pipeline\n",
    "logistic_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Escalado\n",
    "    ('logistic', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Escalado\n",
    "    ('svm', SVC())\n",
    "])\n",
    "\n",
    "# Grid Search para Logistic Regression\n",
    "logistic_grid = GridSearchCV(logistic_pipeline, logistic_params, cv=5, scoring='accuracy')\n",
    "logistic_grid.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros y la precisión\n",
    "print(f\"Mejores parámetros para Logistic Regression: {logistic_grid.best_params_}\")\n",
    "print(f\"Mejor accuracy para Logistic Regression: {logistic_grid.best_score_:.4f}\")\n",
    "\n",
    "# Grid Search para SVM\n",
    "svm_grid = GridSearchCV(svm_pipeline, svm_params, cv=5, scoring='accuracy')\n",
    "svm_grid.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros y la precisión\n",
    "print(f\"Mejores parámetros para SVM: {svm_grid.best_params_}\")\n",
    "print(f\"Mejor accuracy para SVM: {svm_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluar en el conjunto de prueba\n",
    "logistic_best = logistic_grid.best_estimator_\n",
    "svm_best = svm_grid.best_estimator_\n",
    "\n",
    "y_pred_logistic = logistic_best.predict(X_test)\n",
    "y_pred_svm = svm_best.predict(X_test)\n",
    "\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"Accuracy en el conjunto de prueba para Logistic Regression: {accuracy_logistic:.4f}\")\n",
    "print(f\"Accuracy en el conjunto de prueba para SVM: {accuracy_svm:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting Classifier</td>\n",
       "      <td>0.635887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.623295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.558237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Accuracy\n",
       "2  Voting Classifier  0.635887\n",
       "1  Gradient Boosting  0.623295\n",
       "0      Random Forest  0.558237"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Definir otros modelos para probar\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "}\n",
    "\n",
    "# Entrenar y evaluar los nuevos modelos\n",
    "results = []\n",
    "for model_name, model in models.items():\n",
    "    # Definir un pipeline con escalado\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calcular la precisión\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Almacenar los resultados\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy\n",
    "    })\n",
    "\n",
    "# Ahora, usando Voting Classifier\n",
    "voting_model = VotingClassifier(estimators=[\n",
    "    ('logistic', LogisticRegression(C=0.1, solver='liblinear', max_iter=1000)),\n",
    "    ('svm', SVC(C=0.1, kernel='linear')),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "], voting='hard')\n",
    "\n",
    "# Entrenar el Voting Classifier\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred_voting = voting_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión\n",
    "voting_accuracy = accuracy_score(y_test, y_pred_voting)\n",
    "\n",
    "# Almacenar los resultados del Voting Classifier\n",
    "results.append({\n",
    "    'Model': 'Voting Classifier',\n",
    "    'Accuracy': voting_accuracy\n",
    "})\n",
    "\n",
    "# Convertir los resultados a DataFrame y ordenarlos\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "# Mostrar los resultados\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de XGBoost: 0.5637\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Codificar la variable objetivo\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(target)  # target_data es tu variable objetivo original\n",
    "\n",
    "\n",
    "# Dividir el conjunto de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir el modelo XGBoost\n",
    "xgb_model = XGBClassifier(eval_metric='mlogloss', use_label_encoder=False, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión\n",
    "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Mostrar la precisión\n",
    "print(f'Accuracy de XGBoost: {xgb_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1404, number of negative: 2428\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 524\n",
      "[LightGBM] [Info] Number of data points in the train set: 3832, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.366388 -> initscore=-0.547743\n",
      "[LightGBM] [Info] Start training from score -0.547743\n",
      "Accuracy del modelo LightGBM: 0.57\n"
     ]
    }
   ],
   "source": [
    "# Importar las librerías necesarias\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer  # Puedes reemplazar esto con tu propio conjunto de datos\n",
    "\n",
    "\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear el modelo LightGBM con los hiperparámetros adecuados\n",
    "model = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    objective='binary',  # Clasificación binaria\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=31,\n",
    "    max_depth=-1,\n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "# Entrenar el modelo manualmente con parada temprana\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric='binary_error'\n",
    ")\n",
    "\n",
    "# Predecir los valores del conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión (accuracy)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy del modelo LightGBM: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros para CatBoost: {'depth': 6, 'iterations': 500, 'learning_rate': 0.01}\n",
      "Mejor accuracy para CatBoost: 0.6370\n",
      "Accuracy en el conjunto de prueba para CatBoost: 0.6096\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Approved       0.62      0.97      0.75       591\n",
      "    Rejected       0.36      0.02      0.05       367\n",
      "\n",
      "    accuracy                           0.61       958\n",
      "   macro avg       0.49      0.50      0.40       958\n",
      "weighted avg       0.52      0.61      0.48       958\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importar las librerías necesarias\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar las características\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Definir el modelo CatBoost\n",
    "catboost_model = CatBoostClassifier(\n",
    "    iterations=1000,  # Número máximo de iteraciones\n",
    "    learning_rate=0.1,\n",
    "    depth=6,  # Profundidad del árbol\n",
    "    verbose=0,  # Silenciar el output de entrenamiento\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# Definir los parámetros para Grid Search\n",
    "catboost_params = {\n",
    "    'iterations': [500, 1000],  # Puedes ajustar esto\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'depth': [4, 6, 8, 10]\n",
    "}\n",
    "\n",
    "# Grid Search para CatBoost\n",
    "catboost_grid = GridSearchCV(catboost_model, catboost_params, cv=5, scoring='accuracy')\n",
    "catboost_grid.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros y la precisión\n",
    "print(f\"Mejores parámetros para CatBoost: {catboost_grid.best_params_}\")\n",
    "print(f\"Mejor accuracy para CatBoost: {catboost_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluar en el conjunto de prueba\n",
    "catboost_best = catboost_grid.best_estimator_\n",
    "y_pred_catboost = catboost_best.predict(X_test)\n",
    "\n",
    "# Calcular y mostrar la precisión\n",
    "accuracy_catboost = accuracy_score(y_test, y_pred_catboost)\n",
    "print(f\"Accuracy en el conjunto de prueba para CatBoost: {accuracy_catboost:.4f}\")\n",
    "\n",
    "# Imprimir un informe de clasificación\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(y_test, y_pred_catboost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CatBoostClassifier' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, target_data, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Entrenar y evaluar cada modelo\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# Hacer predicciones\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CatBoostClassifier' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "# Supongamos que tenemos una función para eliminar outliers\n",
    "def remove_outliers(df, threshold=3):\n",
    "    # Eliminar filas con valores fuera del rango del umbral de desviación estándar\n",
    "    return df[(np.abs(df - df.mean()) / df.std()) < threshold].dropna()\n",
    "\n",
    "# Definir los modelos\n",
    "models = CatBoostClassifier(\n",
    "            depth=6,\n",
    "            iterations=500,\n",
    "            learning_rate=0.01,\n",
    "            class_weights={0: 1, 1: 3},  # Ajusta según el desbalance en tus datos\n",
    "            eval_metric='F1',\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "# Definir escaladores\n",
    "scalers = {\n",
    "    'No Scaling': None,\n",
    "    'Standardization': StandardScaler(),\n",
    "    'Normalization': MinMaxScaler()\n",
    "}\n",
    "\n",
    "# Definir diferentes conjuntos de características\n",
    "feature_sets = {\n",
    "    'All Features': features,\n",
    "    'No Family Size': features.drop(columns=['dependents']) # Cambia esto según el nombre exacto de la columna\n",
    "}\n",
    "\n",
    "# Inicializar lista para almacenar los resultados\n",
    "results = []\n",
    "\n",
    "# Loop para entrenar modelos con diferentes combinaciones\n",
    "for outliers_option in ['With Outliers', 'Without Outliers']:\n",
    "    # Eliminar outliers si corresponde\n",
    "    data = features.copy()\n",
    "    if outliers_option == 'Without Outliers':\n",
    "        data = remove_outliers(data)\n",
    "    \n",
    "    # Obtener las etiquetas (target) correspondientes\n",
    "    target_data = target.loc[data.index]\n",
    "\n",
    "    for scaling_option, scaler in scalers.items():\n",
    "        # Escalar los datos si corresponde\n",
    "        scaled_data = data.copy()\n",
    "        if scaler:\n",
    "            scaled_data = pd.DataFrame(scaler.fit_transform(scaled_data), columns=data.columns)\n",
    "        \n",
    "        for feature_set_name, feature_set in feature_sets.items():\n",
    "            # Usar las características correspondientes\n",
    "            if feature_set_name == 'All Features':\n",
    "                X = scaled_data\n",
    "            else:\n",
    "                X = scaled_data[feature_set.columns]\n",
    "\n",
    "            # Dividir el conjunto de datos\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, target_data, test_size=0.2, random_state=42)\n",
    "\n",
    "            # Entrenar y evaluar cada modelo\n",
    "            for model_name, model in models.items():\n",
    "                # Entrenar el modelo\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                # Hacer predicciones\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                # Calcular la precisión\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "                # Almacenar los resultados\n",
    "                results.append({\n",
    "                    'Model': model_name,\n",
    "                    'Outliers': outliers_option,\n",
    "                    'Scaling': scaling_option,\n",
    "                    'Feature Set': feature_set_name,\n",
    "                    'Accuracy': accuracy\n",
    "                })\n",
    "\n",
    "# Convertir la lista de resultados a un DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n",
    "# Mostrar los resultados\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Outliers</th>\n",
       "      <th>Scaling</th>\n",
       "      <th>Feature Set</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.572928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.572928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.572928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.567681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.567681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>Without Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.567681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.566806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.566806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.566806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.556367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.556367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>With Outliers</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>No Family Size</td>\n",
       "      <td>0.556367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model          Outliers          Scaling     Feature Set  Accuracy\n",
       "0   CatBoost  Without Outliers       No Scaling    All Features  0.572928\n",
       "1   CatBoost  Without Outliers  Standardization    All Features  0.572928\n",
       "2   CatBoost  Without Outliers    Normalization    All Features  0.572928\n",
       "3   CatBoost  Without Outliers       No Scaling  No Family Size  0.567681\n",
       "4   CatBoost  Without Outliers  Standardization  No Family Size  0.567681\n",
       "5   CatBoost  Without Outliers    Normalization  No Family Size  0.567681\n",
       "6   CatBoost     With Outliers       No Scaling    All Features  0.566806\n",
       "7   CatBoost     With Outliers  Standardization    All Features  0.566806\n",
       "8   CatBoost     With Outliers    Normalization    All Features  0.566806\n",
       "9   CatBoost     With Outliers       No Scaling  No Family Size  0.556367\n",
       "10  CatBoost     With Outliers  Standardization  No Family Size  0.556367\n",
       "11  CatBoost     With Outliers    Normalization  No Family Size  0.556367"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Supongamos que tenemos una función para eliminar outliers\n",
    "def remove_outliers(df, threshold=3):\n",
    "    return df[(np.abs(df - df.mean()) / df.std()) < threshold].dropna()\n",
    "\n",
    "# Convertir etiquetas a numéricas\n",
    "label_encoder = LabelEncoder()\n",
    "target_encoded = label_encoder.fit_transform(target)  # Asegúrate de que 'target' sea tu serie de etiquetas original\n",
    "\n",
    "# Definir el modelo\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000,  # Número máximo de iteraciones\n",
    "    learning_rate=0.1,\n",
    "    depth=6,  # Profundidad del árbol\n",
    "    verbose=0,  # Silenciar el output de entrenamiento\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# Definir escaladores\n",
    "scalers = {\n",
    "    'No Scaling': None,\n",
    "    'Standardization': StandardScaler(),\n",
    "    'Normalization': MinMaxScaler()\n",
    "}\n",
    "\n",
    "# Definir diferentes conjuntos de características\n",
    "feature_sets = {\n",
    "    'All Features': features,\n",
    "    'No Family Size': features.drop(columns=['dependents'])  # Cambia esto según el nombre exacto de la columna\n",
    "}\n",
    "\n",
    "# Inicializar lista para almacenar los resultados\n",
    "results = []\n",
    "\n",
    "# Loop para entrenar modelos con diferentes combinaciones\n",
    "for outliers_option in ['With Outliers', 'Without Outliers']:\n",
    "    # Eliminar outliers si corresponde\n",
    "    data = features.copy()\n",
    "    if outliers_option == 'Without Outliers':\n",
    "        data = remove_outliers(data)\n",
    "    \n",
    "    # Obtener las etiquetas (target) correspondientes\n",
    "    target_data = target_encoded[features.index.intersection(data.index)]  # Asegúrate de que las etiquetas correspondan\n",
    "\n",
    "    for scaling_option, scaler in scalers.items():\n",
    "        # Escalar los datos si corresponde\n",
    "        scaled_data = data.copy()\n",
    "        if scaler:\n",
    "            scaled_data = pd.DataFrame(scaler.fit_transform(scaled_data), columns=data.columns)\n",
    "        \n",
    "        for feature_set_name, feature_set in feature_sets.items():\n",
    "            # Usar las características correspondientes\n",
    "            if feature_set_name == 'All Features':\n",
    "                X = scaled_data\n",
    "            else:\n",
    "                X = scaled_data[feature_set.columns]\n",
    "\n",
    "            # Dividir el conjunto de datos\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, target_data, test_size=0.2, random_state=42)\n",
    "\n",
    "            # Entrenar y evaluar el modelo\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Hacer predicciones\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Calcular la precisión\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            # Almacenar los resultados\n",
    "            results.append({\n",
    "                'Model': 'CatBoost',\n",
    "                'Outliers': outliers_option,\n",
    "                'Scaling': scaling_option,\n",
    "                'Feature Set': feature_set_name,\n",
    "                'Accuracy': accuracy\n",
    "            })\n",
    "\n",
    "# Convertir la lista de resultados a un DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Mostrar los resultados\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 82\u001b[0m\n\u001b[1;32m     71\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     72\u001b[0m     model,\n\u001b[1;32m     73\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_dist,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     79\u001b[0m )\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Entrenar y evaluar el modelo\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Hacer predicciones\u001b[39;00m\n\u001b[1;32m     85\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m random_search\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_finalp/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_finalp/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_finalp/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1959\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1961\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_finalp/lib/python3.11/site-packages/sklearn/model_selection/_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    961\u001b[0m         )\n\u001b[1;32m    962\u001b[0m     )\n\u001b[0;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_finalp/lib/python3.11/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_finalp/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_finalp/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_finalp/lib/python3.11/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_finalp/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_finalp/lib/python3.11/site-packages/catboost/core.py:5201\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5199\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5201\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5202\u001b[0m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5203\u001b[0m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_finalp/lib/python3.11/site-packages/catboost/core.py:2396\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2393\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2395\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2396\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2404\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2405\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_finalp/lib/python3.11/site-packages/catboost/core.py:1776\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1776\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1777\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4833\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4882\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Supongamos que tenemos una función para eliminar outliers\n",
    "def remove_outliers(df, threshold=3):\n",
    "    return df[(np.abs(df - df.mean()) / df.std()) < threshold].dropna()\n",
    "\n",
    "# Convertir etiquetas a numéricas\n",
    "label_encoder = LabelEncoder()\n",
    "target_encoded = label_encoder.fit_transform(target)  # Asegúrate de que 'target' sea tu serie de etiquetas original\n",
    "\n",
    "# Definir el modelo base\n",
    "model = CatBoostClassifier(eval_metric='F1', verbose=False)\n",
    "\n",
    "# Definir el espacio de hiperparámetros para RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'iterations': [100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'l2_leaf_reg': [1, 3, 5, 10],\n",
    "    'class_weights': [{0: 1, 1: 1}, {0: 1, 1: 2}, {0: 1, 1: 3}]  # Ajusta según el desbalance en tus datos\n",
    "}\n",
    "\n",
    "# Definir escaladores\n",
    "scalers = {\n",
    "    'No Scaling': None,\n",
    "    'Standardization': StandardScaler(),\n",
    "    'Normalization': MinMaxScaler()\n",
    "}\n",
    "\n",
    "# Definir diferentes conjuntos de características\n",
    "feature_sets = {\n",
    "    'All Features': features,\n",
    "    'No Family Size': features.drop(columns=['dependents'])  # Cambia esto según el nombre exacto de la columna\n",
    "}\n",
    "\n",
    "# Inicializar lista para almacenar los resultados\n",
    "results = []\n",
    "\n",
    "# Loop para entrenar modelos con diferentes combinaciones\n",
    "for outliers_option in ['With Outliers', 'Without Outliers']:\n",
    "    # Eliminar outliers si corresponde\n",
    "    data = features.copy()\n",
    "    if outliers_option == 'Without Outliers':\n",
    "        data = remove_outliers(data)\n",
    "\n",
    "    # Obtener las etiquetas (target) correspondientes\n",
    "    target_data = target_encoded[features.index.intersection(data.index)]  # Asegúrate de que las etiquetas correspondan\n",
    "\n",
    "    for scaling_option, scaler in scalers.items():\n",
    "        # Escalar los datos si corresponde\n",
    "        scaled_data = data.copy()\n",
    "        if scaler:\n",
    "            scaled_data = pd.DataFrame(scaler.fit_transform(scaled_data), columns=data.columns)\n",
    "\n",
    "        for feature_set_name, feature_set in feature_sets.items():\n",
    "            # Usar las características correspondientes\n",
    "            if feature_set_name == 'All Features':\n",
    "                X = scaled_data\n",
    "            else:\n",
    "                X = scaled_data[feature_set.columns]\n",
    "\n",
    "            # Dividir el conjunto de datos\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, target_data, test_size=0.2, random_state=42)\n",
    "\n",
    "            # Configurar RandomizedSearchCV\n",
    "            random_search = RandomizedSearchCV(\n",
    "                model,\n",
    "                param_distributions=param_dist,\n",
    "                n_iter=50,  # Número de combinaciones a probar\n",
    "                scoring='accuracy',\n",
    "                cv=3,\n",
    "                verbose=0,\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "            # Entrenar y evaluar el modelo\n",
    "            random_search.fit(X_train, y_train)\n",
    "\n",
    "            # Hacer predicciones\n",
    "            y_pred = random_search.predict(X_test)\n",
    "\n",
    "            # Calcular la precisión\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            # Almacenar los resultados\n",
    "            results.append({\n",
    "                'Model': 'CatBoost',\n",
    "                'Outliers': outliers_option,\n",
    "                'Scaling': scaling_option,\n",
    "                'Feature Set': feature_set_name,\n",
    "                'Best Parameters': random_search.best_params_,\n",
    "                'Accuracy': accuracy\n",
    "            })\n",
    "\n",
    "# Convertir la lista de resultados a un DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Mostrar los resultados\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_finalp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
